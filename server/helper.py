import json
import numpy as np
from gpt4all import GPT4All
from nomic import embed


# System prompts
system_prompt_symptom_inquiry = (
    "System Prompt: you are a simple medical assistant.\n"
    "You will be given a question that is generated by a medical diagnosis system.\n"
    "Your job is to rephrase that question because you are going to be communicating on behalf of the system.\n"
    "Do not add any other sentence from yourself.\n"
    "Example input: |user| are you experiencing tightness in you neck and shoulders? |user|"
    "Example output: |assistant| Are you feeling a strain or tightness in your neck and shoulder muscles? |assistant|"
)

system_prompt_treatment_suggestion = (
    "System Prompt: you are a simple medical assistant.\n"
    "You will be given a treatment in the form of keywords that are generated by a medical diagnosis system.\n"
    "Your job is to rephrase this treatment in better and professional words because you are going to be communicating on behalf of the system.\n"
    "Do not add any other sentence from yourself.\n"
    "You should maintain a confident tone.\n"
    "Give your response in HTML format"
    "Example output: |assistant| Treatment: \n [treatments] in bullet points \n [brief explanation] |assistant|"
)

model_path = r"E:\Personal Projects\LLM Prac\Models"

llm = GPT4All("Phi-3-mini-4k-instruct.Q4_0.gguf", model_path=model_path)

def embedText(text):
    return embed.text(text, inference_mode="local")['embeddings']

def enrichUserInput(user_input,client_state):
    if client_state.get('is_initail_prompt'):
        client_state['initial_prompt'] = user_input
    else:
        embededInput=embedText([user_input])[0]
        positiveEmbedding=embedText(["Yes"])[0]
        askedSymptoms=client_state.get('asked_symptoms')
        depth=client_state.get('depth')
        symptomIsPositive=cosine_similarity(embededInput,positiveEmbedding) > 0.6
        if symptomIsPositive:
            client_state['initial_prompt']=client_state['initial_prompt'] + f". I am also experiencing {askedSymptoms[depth-1]}"
    return client_state

def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """Compute the cosine similarity between two vectors."""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def ask_symptom_stream(prompt: str, max_tokens: int = 150):
    """Generator that yields tokens from LLM response for symptom inquiry."""
    with llm.chat_session(system_prompt=system_prompt_symptom_inquiry):
        for token in llm.generate(prompt, max_tokens=max_tokens, streaming=True):
            yield json.dumps({'token': token}) + '\n'

def suggest_treatment_stream(prompt: str, max_tokens: int = 150):
    """Generator that yields tokens from LLM response for treatment suggestions."""
    with llm.chat_session(system_prompt=system_prompt_treatment_suggestion):
        for token in llm.generate(prompt, max_tokens=max_tokens, streaming=True):
            yield json.dumps({'token': token}) + '\n'